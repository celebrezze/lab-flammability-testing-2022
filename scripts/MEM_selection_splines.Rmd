---
title: 'Mixed Effects Model Selection 2: Testing New Random Effect Structure'
author: "Joe Celebrezze"
date: "2024-03-02"
output: html_document
---

# Setup
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(here)
library(lmerTest)
library(cAIC4)
library(mgcv)
here = here::here
source(here("scripts", "source_code.R"))

source(here('scripts', 'mem.selection.function.R')) #this is where all functions for the MEM and GLMM selections are written
```

# Data Structure

For the linear mixed effects models, we are going to be using the *flammability metrics* below as **dependent variables**:

- Flame height (fh)
- Flame duration (fd)
- Change in temp. (temp_change)
- Change in heat flux (heat_flux_change)

The following variables are not going to be considered (with the reasoning behind omitting each one described below):

- Time to ignition (tti): because this variable is conceptually meaningless for all manual ignitions (the majority of ignitions)
- Post-flame glow (pfg): because we do not necessarily trust the glow end time, as it was challenging to see in video playbacks when the sample stopped glowing. Because of this drawback, we relied on the people present during the flammability lab testing to clap at the end of the glow time, but the timing of this clap did not always correspond with the exact end of glowing
- Proportion ignited (prop_ig): because this variable has only one value for each species which does not fit the structure of the models

We have a plethora of variables that could be used as predictors and also a lot of potential covariates. The potential **predictors** are grouped and listed below:

*Hydration or dryness*:
- LFM (can be total LFM, leaf LFM and/or stem LFM)
- Water potential (mpa)
- Wet weight (ww_flam_sample)* (note that this was determined to be more reminiscent of sample weight than wetness, so may not be included in the model selection)
- Dry weight (dw_flam_sample)* (note that this was determined to be more reminiscent of sample weight than dryness, so may not be included in the model selection)

*Leaf morphology*:
- LMA or SLA
- Leaf area (likely unnecessary, as described by LMA and SLA in some capacity)
- Leaf thickness

*Sample morphology*:
- Branching
- Sample density
- Branch height
- Stem to leaf ratio
- Sample weight* (note: this could also be considered a covariate)

Potential **covariates**:

- Starting temperature (start_temp)
- Sample weight* (see note above)
- Sample volume (branch_volume): could also split by height, width and length (although length is mostly the same across samples)
- Ambient humidity or temperature (note: I don't necessarily trust that the meter was doing a good job gathering this data, as it seems like the temperature of the chamber affected the measurements)
- Thermocoupler and hot plate height: probably not necessary, as exploratory analyses showed that there weren't any major differences between variables depending on the thermocoupler height or hot plate height

**Random effect**:

For this model selection, we opted for a nested random effects structure with species and plant ID, as such (1|species/plant_id)
- Species: factor describing species tested
- Plant ID (to account for repeated measurements): note that we will need to make a unique identifier for each plant by combining current columns 'species' and 'plant'. Otherwise, the model will assume that (for example) plant 1 is the same group, treating HETARB 1 and SALLEU 1 as similar when they should not be treated as similar

Looking at the above variables to see how they're situated in the dataset:
```{r}
flamm.df %>% 
  summarise(sw = mean(sample_wt), sw.sd = sd(sample_wt))

# Grouping by plant_id; to check to see which traits do not have any variation per plant_id
trait.summary.plant_id <- flamm.df %>%  
  unite('plant_id', c(species, plant), sep = '_', remove = F) %>% 
  select(fh, species, lfm, leaf_lfm, stem_lfm, mpa, ww_flam_sample, dw_flam_sample, LMA, SLA, thickness, leaf_area, branching, stem_mass_ratio, leaf_mass_ratio, sample_wt, start_temp, branch_volume, branch_height, sample_density, ambient_humidity, ambient_temp, thermocoupler_height, hotplate_height, plant_id) %>% 
  mutate(lfm = scale(lfm), mpa = scale(mpa), ww_flam_sample = scale(ww_flam_sample),
         dw_flam_sample = scale(dw_flam_sample), LMA = scale(LMA), thickness = scale(thickness),
         leaf_area = scale(leaf_area), branching = scale(branching),
         leaf_mass_ratio = scale(leaf_mass_ratio), sample_wt = scale(sample_wt),
         start_temp = scale(start_temp), branch_volume = scale(branch_volume),
         sample_density = scale(sample_density), branch_height = scale(branch_height)) %>%  # scaling traits we want to look at so that standard deviations are comparable
  group_by(plant_id) %>% 
  dplyr::summarise(sd_lfm = sd(lfm), sd_mpa = sd(mpa), sd_ww = sd(ww_flam_sample), sd_dw = sd(dw_flam_sample),
                   sd_lma = sd(LMA), sd_thickness = sd(thickness), sd_leafarea = sd(leaf_area),
                   sd_branching = sd(branching), sd_leafratio = sd(leaf_mass_ratio), sd_sw = sd(sample_wt),
                   sd_st = sd(start_temp), sd_volume = sd(branch_volume),
                   sd_density = sd(sample_density), sd_bh = sd(branch_height))
trait.summary.plant_id %>% 
  mutate(sd_lfm = ifelse(is.na(sd_lfm), 0, sd_lfm),
         sd_mpa = ifelse(is.na(sd_mpa), 0, sd_mpa),
         sd_ww = ifelse(is.na(sd_ww), 0, sd_ww),
         sd_dw = ifelse(is.na(sd_dw), 0, sd_dw),
         sd_lma = ifelse(is.na(sd_lma), 0, sd_lma),
         sd_thickness = ifelse(is.na(sd_thickness), 0, sd_thickness),
         sd_leafarea = ifelse(is.na(sd_leafarea), 0, sd_leafarea),
         sd_branching = ifelse(is.na(sd_branching), 0, sd_branching),
         sd_leafratio = ifelse(is.na(sd_leafratio), 0, sd_leafratio),
         sd_sw = ifelse(is.na(sd_sw), 0, sd_sw),
         sd_st = ifelse(is.na(sd_st), 0, sd_st), 
         sd_volume = ifelse(is.na(sd_volume), 0, sd_volume),
         sd_density = ifelse(is.na(sd_density), 0, sd_density),
         sd_bh = ifelse(is.na(sd_bh), 0, sd_bh)) %>% 
  summary()

# Grouping by species; to check to see which traits do not have any intraspecific variation
trait.summary.species <- flamm.df %>%  # scaling so that standard deviations are comparable
  select(fh, species, lfm, leaf_lfm, stem_lfm, mpa, ww_flam_sample, dw_flam_sample, LMA, SLA, thickness, leaf_area, branching, stem_mass_ratio, leaf_mass_ratio, sample_wt, start_temp, branch_volume, sample_density, ambient_humidity, ambient_temp, thermocoupler_height, hotplate_height) %>% 
  mutate(lfm = scale(lfm), mpa = scale(mpa), ww_flam_sample = scale(ww_flam_sample),
         dw_flam_sample = scale(dw_flam_sample), LMA = scale(LMA), thickness = scale(thickness),
         leaf_area = scale(leaf_area), branching = scale(branching),
         leaf_mass_ratio = scale(leaf_mass_ratio), sample_wt = scale(sample_wt),
         start_temp = scale(start_temp), branch_volume = scale(branch_volume),
         sample_density = scale(sample_density)) %>%  # scaling traits we want to look at so that standard deviations are comparable
  group_by(species) %>% 
  dplyr::summarise(sd_lfm = sd(lfm), sd_mpa = sd(mpa), sd_ww = sd(ww_flam_sample), sd_dw = sd(dw_flam_sample),
                   sd_lma = sd(LMA), sd_thickness = sd(thickness), sd_leafarea = sd(leaf_area),
                   sd_branching = sd(branching), sd_leafratio = sd(leaf_mass_ratio), sd_sw = sd(sample_wt),
                   sd_st = sd(start_temp), sd_volume = sd(branch_volume),
                   sd_density = sd(sample_density))
trait.summary.species %>% 
  mutate(sd_lfm = ifelse(is.na(sd_lfm), 0, sd_lfm),
         sd_mpa = ifelse(is.na(sd_mpa), 0, sd_mpa),
         sd_ww = ifelse(is.na(sd_ww), 0, sd_ww),
         sd_dw = ifelse(is.na(sd_dw), 0, sd_dw),
         sd_lma = ifelse(is.na(sd_lma), 0, sd_lma),
         sd_thickness = ifelse(is.na(sd_thickness), 0, sd_thickness),
         sd_leafarea = ifelse(is.na(sd_leafarea), 0, sd_leafarea),
         sd_branching = ifelse(is.na(sd_branching), 0, sd_branching),
         sd_leafratio = ifelse(is.na(sd_leafratio), 0, sd_leafratio),
         sd_sw = ifelse(is.na(sd_sw), 0, sd_sw),
         sd_st = ifelse(is.na(sd_st), 0, sd_st), 
         sd_volume = ifelse(is.na(sd_volume), 0, sd_volume),
         sd_density = ifelse(is.na(sd_density), 0, sd_density)) %>% 
  summary()
```

The following plant traits are measured for each plant_id (sd = 0 for plant_id):
LFM/stem LFM/leaf LFM, LMA/SLA, thickness, leaf area, leaf ratio/stem ratio

vs. the following traits which have unique values for each plant_id:
MPa, wet weight/dry weight (note: LFM used in calculation), branching, sample weight, starting temp., sample volume

# Initial Collinearity Check
Because we have so many variables, we should look at a correlation matrix to determine which variables to include and which ones we could get rid of right away
```{r}
flamm.df <- flamm.df %>% 
  drop_na(fh, fd, pfg, temp_change, heat_flux_change) # dropping any NA's for flam. metrics

flamm.df %>% 
  select(fh, fd, pfg, temp_change, heat_flux_change, species, lfm, leaf_lfm, stem_lfm, mpa, ww_flam_sample, dw_flam_sample, LMA, SLA, thickness, leaf_area, branching, stem_mass_ratio, leaf_mass_ratio, sample_wt, start_temp, branch_volume, sample_density, ambient_humidity, ambient_temp, branch_height, thermocoupler_height, hotplate_height, stem_sav, leaf_sav, stem_dmc, dmc, leaf_dmc, dw_sppdev) %>% 
  ggcorr(label = T)
```

From the above correlation matrix, there are some initial 'problem areas':
- Sample weight and dw_flam_sample and ww_flam_sample: makes sense since sample weight was used in the calculation of these variables
- Branch volume/branch height and sample weight, dw_flam_sample, ww_flam_sample: all describe bulkiness, size of sample in some way
- LMA and SLA: duh
- Leaf mass ratio and stem mass ratio: also, duh
- Stem LFM and LFM
- Leaf area and dw_flam_sample and ww_flam_sample: more of a surprising one to me, but makes sense conceptually
- Stem LFM and Stem dmc
- LFM and DMC

So, we will eliminate some variables from contention right away:
- SLA: we can use LMA
- Stem mass ratio: we can use leaf mass ratio
- Stem LFM and leaf LFM: unless we notice something in the EDA that suggests otherwise, I think using total LFM makes sense
- Wet weight and dry weight: although these were initially thought to be important variables based on previous studies looking at tissue-level flammability, a first pass of the MEM selection showed that the sample weight component of either of these metrics was far outweighing the 'wetness' or 'dryness' component of them represented by LFM. We believe that leaving them in can be misleading to people as wet weight signifies that an increase means an increased hydration, when in many cases, it just meant an increase in weight
- Leaf area: because leaf area is included in some fashion in the calculation of LMA and due to it's oddly strong correlation to dw_flam_sample and ww_flam_sample which we're interested in keeping in the models, it makes sense to remove

We can also eliminate ambient temp and humidity since they show absolutely no correlation with flame height (and very little correlation with most variables)

# Model Selection
The model selection is going to be based on minimizing AIC to select the most parsimonious models. If the difference in AIC is less than 2, then models are statistically similar and should be considered in tandem. In these cases, I opted to select the model with the variables that most commonly occurred in the identified 'most parsimonious' models. See the below methods, extracted from the manuscript draft (March 12, 2024) for more details.

Linear mixed effects models were used to understand the response of flammability metrics (flame height, flame duration, temperature change and heat flux change) to plant traits (see Table 1) and covariates using the lme4 package (Bates et al., 2015). Covariates included sample mass, sample volume, and starting temperature. To account for the repeated measures design, plant ID was included as a random effect nested within a factor representing species. An information-criteria-based model selection was utilized to identify the highest performing model(s) for each flammability metric. The model selection process followed: (1) generating models using every possible permutation of explanatory variables including all possible first-order interaction terms, using maximum likelihood models; (2) excluding models with multicollinear predictors, where the variance inflation factor (VIF) was greater than 5 (White and Zipperer, 2010); (3) calculating the Akaike Information Criterion (AIC; Akaike, 1974); and (4) selecting the most parsimonious models (i.e., the models with the lowest AIC). When multiple parsimonious models were selected (i.e., when ΔAIC < 2), explanatory variables present in >66% of models were included in the ‘top performing model’, as presented in the figure. The beta coefficients for each explanatory variable were determined with a restricted maximum likelihood linear mixed effects model.

Relationships between significant plant traits and each flammability metric were then visualized and investigated using the remef package (Hohenstein and Kliegl, 2022). Remef involves the removal of partial effects by the adjustment of the outcome variable through subtraction or addition of values determined from selected fixed effects and random effects, using the model of best fit (maximum likelihood mixed effects model). Using this technique, we display underlying relationships more clearly by accounting for the effects of confounding terms. When interpreting relationships between flammability metrics and predictors of interest (plant traits which performed well in our model selection), we applied remef by removing partial effects of all fixed effects, except for the predictor of interest and interaction terms including the predictor of interest, and random effects from the outcome variable (flammability metrics), using the identified ‘best model’. Then, we used scatterplots and linear regressions to visualize relationships between the predictor of interest and the remef-adjusted outcome variable

For the mem.selection() function, note the following things:
y.var must be character vector for flam. variable of interest
predictors must be dataframe w/ only predictors
df must be dataframe w/ all values
rem.str must be character vector; default is simple (1|plant_id)
the output is a list of 2 elements, the first being a dataframe with AIC, BIC, Mallows cp values and the second being a list of the mixed effects models described in the dataframe

Whereas for the mem.int.selection() function, note the following difference:
predictors must be a character vectors with the explanatory variables of interest

## Data Wrangling (MEM)
For main dataset (mem.df):
- Remove non-ignitions
- Add plant_id variable
- Select all potentially 'interesting' variables
- Scale and center them all
- Remove NA's
- Remove ARCDEN and HETARB from the analysis; after removing the above, each of these species had very few datapoints (n = 2 for HETARB, n = 8 for ARCDEN) and the random effects had only 1 datapoint in each category (plant_id) for both plants of HETARB and for 3/4 plants for ARCDEN

For predictors dataset:
- Use wrangled dataset, mem.df
- Select predictors we're interested in including in the mixed effects model selection
```{r}
mem.df <- flamm.df %>% 
  filter(ignition != '0') %>% 
  filter(species != 'ARCDEN', species != 'HETARB') %>% 
  unite('plant_id', c(species, plant), sep = '_', remove = F) %>% 
  select(species, thickness, lfm, leaf_area, LMA, sample_wt, leaf_mass_ratio, branching, mpa,
         ignition, fh, fd, temp_change, heat_flux_change, prop_ig, dw_flam_sample,
         ww_flam_sample, sample_density, branch_volume, start_temp, leaf_area, branch_height,
         stem_dmc, leaf_dmc, dmc, stem_sav, leaf_sav, dw_sppdev, plant_id) %>% 
  mutate(lfm = scale(lfm), mpa = scale(mpa), ww_flam_sample = scale(ww_flam_sample),
         dw_flam_sample = scale(dw_flam_sample), sample_density = scale(sample_density),
         LMA = scale(LMA), thickness = scale(thickness),
         leaf_area = scale(leaf_area), branching = scale(branching),
         leaf_mass_ratio = scale(leaf_mass_ratio), sample_wt = scale(sample_wt),
         start_temp = scale(start_temp), branch_volume = scale(branch_volume),
         fh = scale(fh), fd = scale(fd),
         temp_change = scale(temp_change), heat_flux_change = scale(heat_flux_change),
         leaf_area = scale(leaf_area), branch_height = scale(branch_height),
         stem_dmc = scale(stem_dmc), leaf_dmc = scale(leaf_dmc), dmc = scale(dmc),
         stem_sav = scale(stem_sav), leaf_sav= scale(leaf_sav), dw_sppdev= scale(dw_sppdev)) %>% 
  drop_na(lfm, LMA, sample_wt, leaf_mass_ratio, branching, mpa, start_temp, dmc, branch_volume, stem_sav, leaf_area, leaf_sav, thickness, species)

# Predictors
mem.predictors.df <- mem.df %>% 
  select(lfm, LMA, sample_wt, leaf_mass_ratio, branching, mpa, start_temp, dmc, branch_volume, stem_sav, leaf_sav, thickness) # twelve predictors; nine of which represent hydration, branch morphology, and leaf morphology (plant traits); and the other three are included as covariates (sample mass, sample volume, starting temperature)

# Predictors (as character vecotr)
predictors <- c('lfm', 'sample_wt', 'leaf_mass_ratio', 'branching', 'start_temp', 'dmc', 'branch_volume', 'stem_sav', 'leaf_sav', 'thickness', 'LMA', 'mpa')

# Stepwise Selection
step.mem.df <- mem.df %>% 
    select(lfm, LMA, sample_wt, leaf_mass_ratio, branching, mpa, start_temp, dmc, branch_volume, stem_sav, leaf_sav, thickness, fh, fd, temp_change, heat_flux_change)
```


# in progress
```{r}
woo <- flamm.df %>% 
  filter(ignition != '0') %>% 
  filter(species != 'ARCDEN', species != 'HETARB') %>% 
  unite('plant_id', c(species, plant), sep = '_', remove = F)

inprogress.data <- data.frame(sample_wt = as.vector(woo$sample_wt), fh = as.vector(woo$fh), fd = as.vector(woo$fd), lfm = as.vector(woo$lfm), branching = as.vector(woo$branching), dmc = as.vector(woo$dmc), branch_volume = as.vector(woo$branch_volume), species = as.factor(woo$species)) %>% 
  mutate(log_sw = log(sample_wt))

inprogress.data2 <- data.frame(sample_wt = as.vector(woo$sample_wt), fh = as.vector(woo$fh), fd = as.vector(woo$fd), lfm = as.vector(woo$lfm), branching = 0.4, dmc = as.vector(woo$dmc), branch_volume = as.vector(woo$branch_volume), species = as.factor(woo$species)) %>% 
  mutate(log_sw = 2)

mod1 <- gam(fh ~ s(lfm) + log_sw, se = T, data = inprogress.data)
summary(mod1)
plot(mod1, se = T)



mod2 <- gamm(fd ~ s(branching) + s(lfm, by = species) + log_sw, data = inprogress.data)
summary(mod2$gam)
plot(mod2$gam, se = T, scheme = 2)



mod3 <- gamm(log(fd) ~ s(branching) + lfm*species + log_sw*species, data = inprogress.data)
summary(mod3$gam)
plot(mod3$gam, se = T, scheme = 2)

inprogress.data$predicted.fd <- predict.gam(mod3$gam, newdata = inprogress.data2)

inprogress.data %>% 
  ggplot(aes(x = lfm, y = predicted.fd, color = species)) +
    geom_point()
```







## Flame Height
### a) Two or More Predictors, No Interactions
This function tests all possible permutations of fixed effects, but only tests combinations with at least two predictors, as VIF is not applicable for models with one predictor, so the model selection involving singular predictors was coded as a different function (see b). Note that this function starts to cause R to stall out or abort the session if 14 or more predictors are included in the model selection. Otherwise, it'll take a little while to run, but it shouldn't stall out.
```{r, warning=F, message=F}
aljgfaoef

fh.mem.selection <- mem.selection('fh', mem.predictors.df, mem.df)
fh.model.df <- fh.mem.selection[[1]]  %>% 
  mutate(selection = 'fixed')
fh.mod.list <- fh.mem.selection[[2]]
fh.top.mem <- mem.selection.table(fh.model.df, fh.mod.list, 'FH_MEM2.html') %>% 
  mutate(flam.var = 'fh')
```

### b) One Predictor, No Interactions
This function tests each of the univariate models with the predictors listed in the character vector above
```{r, warning=F, message=F}
fh.univariate.mem <- mem.univariate.selection('fh', predictors, mem.df)
fh.univariate.model.df <- fh.univariate.mem[[1]]  %>% 
  mutate(selection = 'univariate')
```

### c) Interactions Only
This function tests only first-order interaction terms
```{r, warning=F, message=F}
fh.mem.int.selection <- mem.firstorder.int.selection('fh', predictors, mem.df)
fh.int.model.df <- fh.mem.int.selection[[1]] %>% 
  mutate(selection = 'int_only')
fh.int.mod.list <- fh.mem.int.selection[[2]]
```

### d) Interactions and Predictors
This function tests first-order interaction terms, as identified in (c) as well as all combinations of the remaining fixed effects from the predictors dataframe. 
```{r, warning=F, message=F}
fh.mem.int.selection_1 <- mem.int.fixed.selection('fh', c('lfm', 'sample_wt'), mem.predictors.df, mem.df)
fh.int.model.df_1 <- fh.mem.int.selection_1[[1]] %>% 
  mutate(selection = 'fixed_int1')

fh.mem.int.selection_2 <- mem.int.fixed.selection('fh', c('branching', 'sample_wt'), mem.predictors.df, mem.df)
fh.int.model.df_2 <- fh.mem.int.selection_2[[1]] %>% 
  mutate(selection = 'fixed_int2')

fh.mem.int.selection_3 <- mem.int.fixed.selection('fh', c('mpa', 'sample_wt'), mem.predictors.df, mem.df)
fh.int.model.df_3 <- fh.mem.int.selection_3[[1]] %>% 
  mutate(selection = 'fixed_int3')
```

### e) Selection Dataframe
This chunk of code binds the dataframes from the above chunks of code (a-d) and groups them altogether in two dataframes, one with all models and one with the most parsimonious models (minimizing AIC)
```{r}
main.fh.mem.df <- rbind(fh.model.df, fh.univariate.model.df, fh.int.model.df,
                        fh.int.model.df_1, fh.int.model.df_2, fh.int.model.df_3) %>% 
  drop_na(AIC)
top.fh.mem.df <- main.fh.mem.df %>% 
  filter(AIC < min(main.fh.mem.df$AIC) + 2)
```

### f) Stepwise Selections
P-values
```{r}
# Maximal Model (all first-order interaction terms)
max.fh.mem_int <- lmer(fh ~ lfm*LMA + lfm*sample_wt + lfm*leaf_mass_ratio + lfm*branching + lfm*mpa + lfm*start_temp + lfm*dmc + lfm*branch_volume + lfm*stem_sav + lfm*leaf_sav + lfm*thickness + LMA*sample_wt + LMA*leaf_mass_ratio + LMA*branching + LMA*mpa + LMA*start_temp + LMA*dmc + LMA*branch_volume + LMA*stem_sav + LMA*leaf_sav + LMA*thickness + sample_wt*leaf_mass_ratio + sample_wt*branching + sample_wt*mpa + sample_wt*start_temp + sample_wt*dmc + sample_wt*branch_volume + sample_wt*stem_sav + sample_wt*leaf_sav + sample_wt*thickness + leaf_mass_ratio*branching + leaf_mass_ratio*mpa + leaf_mass_ratio*start_temp + leaf_mass_ratio*dmc + leaf_mass_ratio*branch_volume + leaf_mass_ratio*stem_sav + leaf_mass_ratio*leaf_sav + leaf_mass_ratio*thickness + branching*mpa + branching*start_temp + branching*dmc + branching*branch_volume + branching*stem_sav + branching*leaf_sav + branching*thickness + mpa*start_temp + mpa*dmc + mpa*branch_volume + mpa*stem_sav + mpa*leaf_sav + mpa*thickness + start_temp*dmc + start_temp*branch_volume + start_temp*stem_sav + start_temp*leaf_sav + start_temp*thickness + dmc*branch_volume + dmc*stem_sav + dmc*leaf_sav + dmc*thickness + branch_volume*stem_sav + branch_volume*leaf_sav + branch_volume*thickness + stem_sav*leaf_sav + stem_sav*thickness + leaf_sav*thickness + lfm + LMA + sample_wt + leaf_mass_ratio + branching + mpa + start_temp + dmc + branch_volume + stem_sav + leaf_sav + thickness + (1|species/plant_id), mem.df, REML = T)

fh.step_int <- step(max.fh.mem_int, direction = 'both', ddf = 'Kenward-Roger', reduce.random = F)
fh.step_int

# Maximal Model (no interaction terms)
max.fh.mem_fix <- lmer(fh ~ lfm + LMA + sample_wt + leaf_mass_ratio + branching + mpa + start_temp + dmc + branch_volume + stem_sav + leaf_sav + thickness + (1|species/plant_id), mem.df, REML = T)

fh.step_fix <- step(max.fh.mem_fix, direction = 'both', ddf = 'Kenward-Roger', reduce.random = F)
fh.step_fix
```

AIC
direction = 'both' is not working with the random effect structure
```{r}
stepcAIC(max.fh.mem_int, 'backward', groupCandidates = 'species/plant_id')
```

### g) LASSO
I am unable to get the nested random effects structure to work for glmmLasso, so below the LASSO uses plant_id as the random effect on intercept rather than a nested species/plant_id as we are using in our primary model selection
#### g1) Lambda Cross-validation 
from https://davidabugaber.com/blog/f/find-the-optimal-mixed-model-for-your-data-with-glmmlasso
```{r}
#this loop takes much longer to run because there's more random intercepts

#set lambdas... go from 10^-7 to 10^7, in 40 log steps (might take a while)
lambda <- 10^seq(-7,7, length=40)
 
#dummy vectors of model fit values for each lambda: BIC, AIC, prediction error
BIC_vec <- rep(Inf, length(lambda))
AIC_vec <- rep(Inf, length(lambda))
Devianz_ma<-NULL
Coeff_ma<-NULL
 
family = gaussian(link = "identity")
 
j<-1
for (j in 1:length(BIC_vec)){
 print(paste("Iteration ", j, sep=""))
 
 glm1 <- try( #throwing main variables identified by the information criteria model selection into the LASSO cross-validation process; using plant.id as random effect
 glmmLasso(fh ~ lfm:LMA + lfm:sample_wt + lfm:leaf_mass_ratio + lfm:branching + lfm:mpa + lfm:start_temp + lfm:dmc + lfm:branch_volume + lfm:stem_sav + lfm:leaf_sav + lfm:thickness + LMA:sample_wt + LMA:leaf_mass_ratio + LMA:branching + LMA:mpa + LMA:start_temp + LMA:dmc + LMA:branch_volume + LMA:stem_sav + LMA:leaf_sav + LMA:thickness + sample_wt:leaf_mass_ratio + sample_wt:branching + sample_wt:mpa + sample_wt:start_temp + sample_wt:dmc + sample_wt:branch_volume + sample_wt:stem_sav + sample_wt:leaf_sav + sample_wt:thickness + leaf_mass_ratio:branching + leaf_mass_ratio:mpa + leaf_mass_ratio:start_temp + leaf_mass_ratio:dmc + leaf_mass_ratio:branch_volume + leaf_mass_ratio:stem_sav + leaf_mass_ratio:leaf_sav + leaf_mass_ratio:thickness + branching:mpa + branching:start_temp + branching:dmc + branching:branch_volume + branching:stem_sav + branching:leaf_sav + branching:thickness + mpa:start_temp + mpa:dmc + mpa:branch_volume + mpa:stem_sav + mpa:leaf_sav + mpa:thickness + start_temp:dmc + start_temp:branch_volume + start_temp:stem_sav + start_temp:leaf_sav + start_temp:thickness + dmc:branch_volume + dmc:stem_sav + dmc:leaf_sav + dmc:thickness + branch_volume:stem_sav + branch_volume:leaf_sav + branch_volume:thickness + stem_sav:leaf_sav + stem_sav:thickness + leaf_sav:thickness + lfm + LMA + sample_wt + leaf_mass_ratio + branching + mpa + start_temp + dmc + branch_volume + stem_sav + leaf_sav + thickness,
 data=mem.df,
 rnd = list(plant_id=~1), 
 family = gaussian(link = "identity"),
 lambda = lambda[j],
 switch.NR = TRUE,
 final.re = TRUE), 
 silent = TRUE)
 

# code to make it continue anyway if an error occurs
  if(class(glm1)!="try-error")
 { 
 
 #save BIC, AIC
 BIC_vec[j]<-glm1$bic
 AIC_vec[j]<-glm1$aic
 
 #save coefficient outputs
 Coeff_ma<-cbind(Coeff_ma,glm1$coefficients)
 
 #save error (deviance) values
 y.hat<-predict(glm1,mem.df) 
 Devianz_ma[j]<-sum(family$dev.resids(mem.df$fh,y.hat,wt=rep(1,length(y.hat)))) } }

# Best lamdbas, based on different criteria
lambda[which.min(BIC_vec)]
fh_lambda_bic <- lambda[which.min(BIC_vec)]
lambda[which.min(AIC_vec)]
fh_lambda_aic <- lambda[which.min(AIC_vec)]
```

#### g2) Model Selection
```{r}
# AIC-based lambda
fh_lasso_1 <- glmmLasso(fh ~ lfm:LMA + lfm:sample_wt + lfm:leaf_mass_ratio + lfm:branching + lfm:mpa + lfm:start_temp + lfm:dmc + lfm:branch_volume + lfm:stem_sav + lfm:leaf_sav + lfm:thickness + LMA:sample_wt + LMA:leaf_mass_ratio + LMA:branching + LMA:mpa + LMA:start_temp + LMA:dmc + LMA:branch_volume + LMA:stem_sav + LMA:leaf_sav + LMA:thickness + sample_wt:leaf_mass_ratio + sample_wt:branching + sample_wt:mpa + sample_wt:start_temp + sample_wt:dmc + sample_wt:branch_volume + sample_wt:stem_sav + sample_wt:leaf_sav + sample_wt:thickness + leaf_mass_ratio:branching + leaf_mass_ratio:mpa + leaf_mass_ratio:start_temp + leaf_mass_ratio:dmc + leaf_mass_ratio:branch_volume + leaf_mass_ratio:stem_sav + leaf_mass_ratio:leaf_sav + leaf_mass_ratio:thickness + branching:mpa + branching:start_temp + branching:dmc + branching:branch_volume + branching:stem_sav + branching:leaf_sav + branching:thickness + mpa:start_temp + mpa:dmc + mpa:branch_volume + mpa:stem_sav + mpa:leaf_sav + mpa:thickness + start_temp:dmc + start_temp:branch_volume + start_temp:stem_sav + start_temp:leaf_sav + start_temp:thickness + dmc:branch_volume + dmc:stem_sav + dmc:leaf_sav + dmc:thickness + branch_volume:stem_sav + branch_volume:leaf_sav + branch_volume:thickness + stem_sav:leaf_sav + stem_sav:thickness + leaf_sav:thickness + lfm + LMA + sample_wt + leaf_mass_ratio + branching + mpa + start_temp + dmc + branch_volume + stem_sav + leaf_sav + thickness,
 data=mem.df,
 rnd = list(plant_id=~1), 
 family = gaussian(link = "identity"),
 lambda = fh_lambda_aic,
 switch.NR = TRUE,
 final.re = TRUE)

summary(fh_lasso_1)

# BIC-based lambda
fh_lasso_2 <- glmmLasso(fh ~ lfm:LMA + lfm:sample_wt + lfm:leaf_mass_ratio + lfm:branching + lfm:mpa + lfm:start_temp + lfm:dmc + lfm:branch_volume + lfm:stem_sav + lfm:leaf_sav + lfm:thickness + LMA:sample_wt + LMA:leaf_mass_ratio + LMA:branching + LMA:mpa + LMA:start_temp + LMA:dmc + LMA:branch_volume + LMA:stem_sav + LMA:leaf_sav + LMA:thickness + sample_wt:leaf_mass_ratio + sample_wt:branching + sample_wt:mpa + sample_wt:start_temp + sample_wt:dmc + sample_wt:branch_volume + sample_wt:stem_sav + sample_wt:leaf_sav + sample_wt:thickness + leaf_mass_ratio:branching + leaf_mass_ratio:mpa + leaf_mass_ratio:start_temp + leaf_mass_ratio:dmc + leaf_mass_ratio:branch_volume + leaf_mass_ratio:stem_sav + leaf_mass_ratio:leaf_sav + leaf_mass_ratio:thickness + branching:mpa + branching:start_temp + branching:dmc + branching:branch_volume + branching:stem_sav + branching:leaf_sav + branching:thickness + mpa:start_temp + mpa:dmc + mpa:branch_volume + mpa:stem_sav + mpa:leaf_sav + mpa:thickness + start_temp:dmc + start_temp:branch_volume + start_temp:stem_sav + start_temp:leaf_sav + start_temp:thickness + dmc:branch_volume + dmc:stem_sav + dmc:leaf_sav + dmc:thickness + branch_volume:stem_sav + branch_volume:leaf_sav + branch_volume:thickness + stem_sav:leaf_sav + stem_sav:thickness + leaf_sav:thickness + lfm + LMA + sample_wt + leaf_mass_ratio + branching + mpa + start_temp + dmc + branch_volume + stem_sav + leaf_sav + thickness,
 data=mem.df,
 rnd = list(plant_id=~1), 
 family = gaussian(link = "identity"),
 lambda = fh_lambda_bic,
 switch.NR = TRUE,
 final.re = TRUE)

summary(fh_lasso_2)
```
